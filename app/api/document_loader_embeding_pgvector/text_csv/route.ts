/**
 * ===============================================
 * Document Loader, Embedding & PGVector API
 * ===============================================
 * 
 * ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å:
 * - ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data/
 * - ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô embeddings ‡∏î‡πâ‡∏ß‡∏¢ OpenAI
 * - ‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô Supabase Vector Store (pgvector)
 * - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå .txt ‡πÅ‡∏•‡∏∞ .csv
 * - Text splitting ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö chunk ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
 * - ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏´‡∏°‡πà
 * 
 * API Endpoints:
 * - GET: ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings (‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏´‡∏°‡πà)
 * - POST: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢ similarity search
 * - PUT: ‡∏î‡∏π‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô vector store
 * - DELETE: ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô vector store
 */

import { NextRequest, NextResponse } from "next/server"
import { createClient } from "@/lib/server";

// LangChain & AI SDK Imports
import { DirectoryLoader } from "@langchain/classic/document_loaders/fs/directory";
import { TextLoader } from "@langchain/classic/document_loaders/fs/text";
import { CSVLoader } from "@langchain/community/document_loaders/fs/csv"
import { RecursiveCharacterTextSplitter } from "@langchain/textsplitters"
import { SupabaseVectorStore } from "@langchain/community/vectorstores/supabase"
import { GoogleGenerativeAIEmbeddings } from "@langchain/google-genai";
import { CacheBackedEmbeddings } from "@langchain/classic/embeddings/cache_backed";
import { InMemoryStore } from "@langchain/core/stores"

export const dynamic = 'force-dynamic'
export const maxDuration = 60 // ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•

/**
 * GET API: ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô vector store
 */
export async function GET() {
  try {
    console.log("üîÑ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data/...")
    
    // ===============================================
    // Step 0: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤ - Clean Existing Data
    // ===============================================
    const supabase = await createClient();
    
    const { count: existingCount } = await supabase
      .from('documents')
      .select('*', { count: 'exact', head: true });

    if (existingCount && existingCount > 0) {
      console.log(`üóëÔ∏è ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤ ${existingCount} records - ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏Å‡πà‡∏≠‡∏ô...`);
      const { error: deleteError } = await supabase
        .from('documents')
        .delete()
        .neq('id', 0);

      if (deleteError) throw new Error(`‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡πÑ‡∏î‡πâ: ${deleteError.message}`);
      console.log(`‚úÖ ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à`);
    }
    
    // ===============================================
    // Step 1: ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡πÑ‡∏î‡πÄ‡∏£‡πá‡∏Å‡∏ó‡∏≠‡∏£‡∏µ
    // ===============================================
    const rawDocs = await new DirectoryLoader("./data", {
        ".txt": (path) => new TextLoader(path),
        ".csv": (path) => new CSVLoader(path, { column: undefined, separator: "," }),
    }).load();

    if (rawDocs.length === 0) {
      return NextResponse.json({ error: "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data/" }, { status: 400 })
    }

    // ===============================================
    // Step 2: ‡πÅ‡∏¢‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ (Chunking)
    // ===============================================
    const splitter = new RecursiveCharacterTextSplitter({
        chunkSize: 1000,    // ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (Google ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö context ‡πÑ‡∏î‡πâ‡πÄ‡∏¢‡∏≠‡∏∞)
        chunkOverlap: 200,
        separators: ["\n\n", "\n", ",", " "],
    });

    const chunks = await splitter.splitDocuments(rawDocs);
    console.log(`‚úÇÔ∏è ‡πÅ‡∏¢‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô ${chunks.length} ‡∏ä‡∏¥‡πâ‡∏ô`)

    // ===============================================
    // Step 3: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Embeddings ‡πÅ‡∏•‡∏∞ Vector Store
    // ===============================================
    const baseEmbeddings = new GoogleGenerativeAIEmbeddings({ 
      model: process.env.GOOGLE_EMBEDDING_MODEL_NAME || 'text-embedding-004',
      // taskType: TaskType.RETRIEVAL_DOCUMENT, // ‡∏ö‡∏≤‡∏á‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏ TaskType
    });

    const cacheStore = new InMemoryStore();
    const embeddings = CacheBackedEmbeddings.fromBytesStore(
      baseEmbeddings,
      cacheStore,
      { namespace: "document_embeddings" }
    );

    const vectorStore = new SupabaseVectorStore(embeddings, {
        client: supabase,
        tableName: 'documents',
        queryName: 'match_documents' 
    });

    // ===============================================
    // Step 4: ‡πÄ‡∏û‡∏¥‡πà‡∏° Metadata
    // ===============================================
    const chunksWithMetadata = chunks.map((chunk, index) => {
      const source = chunk.metadata.source || 'unknown'
      const filename = source.split('/').pop() || source.split('\\').pop() || 'unknown'
      
      return {
        ...chunk,
        metadata: {
          ...chunk.metadata,
          filename,
          chunk_index: index,
          chunk_size: chunk.pageContent.length,
          timestamp: new Date().toISOString(),
          type: filename.endsWith('.csv') ? 'csv' : 'text'
        }
      }
    })

    // ===============================================
    // Step 5: ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings ‡πÅ‡∏ö‡∏ö Batch (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà Error)
    // ===============================================
    console.log("üîÆ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å (Batch Processing)...")
    
    // ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡∏ô‡∏≤‡∏î Batch ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Timeout / Rate Limit
    const BATCH_SIZE = 50; 
    let processedCount = 0;

    for (let i = 0; i < chunksWithMetadata.length; i += BATCH_SIZE) {
      const batch = chunksWithMetadata.slice(i, i + BATCH_SIZE);
      console.log(`‚ö° ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Batch ${i + 1} - ${Math.min(i + BATCH_SIZE, chunksWithMetadata.length)} ‡∏à‡∏≤‡∏Å ${chunksWithMetadata.length}`);
      
      try {
        await vectorStore.addDocuments(batch);
        processedCount += batch.length;
        
        // (Optional) ‡∏û‡∏±‡∏Å 0.5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏†‡∏≤‡∏£‡∏∞ API
        await new Promise(resolve => setTimeout(resolve, 500)); 
        
      } catch (batchError) {
        console.error(`‚ùå Error ‡πÉ‡∏ô Batch ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô index ${i}:`, batchError);
        // ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡∏à‡∏∞ throw error ‡πÄ‡∏•‡∏¢ ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞‡∏Ç‡πâ‡∏≤‡∏° batch ‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏µ‡∏¢‡πÑ‡∏õ‡∏Å‡πá‡πÑ‡∏î‡πâ
        throw batchError; 
      }
    }
    
    console.log(`‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ${processedCount} chunks ‡πÅ‡∏•‡πâ‡∏ß`)

    // ===============================================
    // Step 6: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
    // ===============================================
    const stats = {
      previous_records: existingCount || 0,
      new_records: processedCount,
      total_documents: rawDocs.length,
      embedding_model: process.env.GOOGLE_EMBEDDING_MODEL_NAME || 'text-embedding-004',
      timestamp: new Date().toISOString()
    }

    return NextResponse.json({ 
      message: `‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• ${processedCount} chunks`,
      stats,
      success: true
    })

  } catch (error) {
    console.error('‚ùå Error ‡πÉ‡∏´‡∏ç‡πà‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•:', error)
    
    return NextResponse.json({ 
      error: '‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£',
      details: error instanceof Error ? error.message : 'Unknown error',
      suggestion: '‡∏•‡∏≠‡∏á‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ç‡∏ô‡∏≤‡∏î Vector Column ‡πÉ‡∏ô Supabase (Google ‡πÉ‡∏ä‡πâ 768, OpenAI ‡πÉ‡∏ä‡πâ 1536)',
      success: false
    }, { status: 500 })
  }
}

/**
 * POST API: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô‡πÉ‡∏ô vector store
 */
export async function POST(req: NextRequest) {
  try {
    const { query, limit = 5 } = await req.json()
    
    if (!query) {
      return NextResponse.json({ 
        error: "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏ query ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤" 
      }, { status: 400 })
    }

    console.log(`üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: "${query}"`)
    console.log("‚ö° ‡πÉ‡∏ä‡πâ CacheBackedEmbeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")

    // ===============================================
    // Setup Vector Store ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
    // ===============================================
    const supabase = await createClient();
    
    const baseEmbeddings = new GoogleGenerativeAIEmbeddings({ 
      model: process.env.GOOGLE_EMBEDDING_MODEL_NAME || 'text-embedding-004',
    });

    // ‡∏™‡∏£‡πâ‡∏≤‡∏á Cache-backed embeddings ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
    const cacheStore = new InMemoryStore();
    const embeddings = CacheBackedEmbeddings.fromBytesStore(
      baseEmbeddings,
      cacheStore,
      {
        namespace: "search_embeddings" // ‡∏Å‡∏≥‡∏´‡∏ô‡∏î namespace ‡πÅ‡∏¢‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
      }
    );

    const vectorStore = new SupabaseVectorStore(embeddings, {
        client: supabase,
        tableName: 'documents',
        queryName: 'match_documents'
    });

    // ===============================================
    // ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô
    // ===============================================
    const results = await vectorStore.similaritySearchWithScore(query, limit)
    
    console.log(`üìã ‡∏û‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: ${results.length} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£`)

    // ===============================================
    // ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    // ===============================================
    const formattedResults = results.map(([doc, score], index) => ({
      rank: index + 1,
      content: doc.pageContent,
      metadata: doc.metadata,
      relevance_score: score
    }))

    return NextResponse.json({
      query,
      results_count: results.length,
      results: formattedResults,
      success: true
    })

  } catch (error) {
    console.error('‚ùå Error ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤:', error)
    
    return NextResponse.json({ 
      error: '‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤',
      details: error instanceof Error ? error.message : 'Unknown error',
      success: false
    }, { status: 500 })
  }
}

/**
 * DELETE API: ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô vector store
 */
export async function DELETE() {
  try {
    const supabase = await createClient();
    
    // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏•‡∏ö
    const { count: existingCount } = await supabase
      .from('documents')
      .select('*', { count: 'exact', head: true });

    if (!existingCount || existingCount === 0) {
      return NextResponse.json({ 
        message: "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• - ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏•‡∏ö",
        deleted_records: 0,
        success: true
      })
    }

    console.log(`üóëÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ${existingCount} records...`);
    
    // ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á documents
    const { error } = await supabase
      .from('documents')
      .delete()
      .neq('id', 0) // ‡∏•‡∏ö‡∏ó‡∏∏‡∏Å‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà id ‡πÑ‡∏°‡πà‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö 0 (‡∏ã‡∏∂‡πà‡∏á‡∏Ñ‡∏∑‡∏≠‡∏ó‡∏∏‡∏Å‡πÅ‡∏ñ‡∏ß)

    if (error) {
      throw new Error(error.message)
    }

    console.log(`‚úÖ ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ${existingCount} records ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à`)

    return NextResponse.json({ 
      message: `‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô vector store ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à - ‡∏•‡∏ö‡πÑ‡∏õ ${existingCount} records`,
      deleted_records: existingCount,
      timestamp: new Date().toISOString(),
      success: true
    })

  } catch (error) {
    console.error('‚ùå Error ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:', error)
    
    return NextResponse.json({ 
      error: '‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•',
      details: error instanceof Error ? error.message : 'Unknown error',
      success: false
    }, { status: 500 })
  }
}

/**
 * PUT API: ‡∏î‡∏π‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô vector store
 */
export async function PUT() {
  try {
    const supabase = await createClient();
    
    // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    const { count: totalCount } = await supabase
      .from('documents')
      .select('*', { count: 'exact', head: true });

    if (!totalCount || totalCount === 0) {
      return NextResponse.json({ 
        message: "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•",
        stats: {
          total_records: 0,
          files_breakdown: [],
          timestamp: new Date().toISOString()
        },
        success: true
      })
    }

    // ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• metadata ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
    const { data: documents } = await supabase
      .from('documents')
      .select('metadata')
      .limit(1000); // ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏¢‡∏≠‡∏∞‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ

    
    // ‡∏Å‡∏≥‡∏´‡∏ô‡∏î interface ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö file stats
    interface FileStats {
      filename: string;
      type: string;
      chunks: number;
      total_chars: number;
    }

    const fileStats = documents?.reduce((acc: Record<string, FileStats>, doc) => {
      const filename = doc.metadata?.filename || 'unknown';
      const type = doc.metadata?.type || 'unknown';
      
      if (!acc[filename]) {
        acc[filename] = {
          filename,
          type,
          chunks: 0,
          total_chars: 0
        };
      }
      
      acc[filename].chunks += 1;
      acc[filename].total_chars += doc.metadata?.chunk_size || 0;
      
      return acc;
    }, {}) || {};

    const stats = {
      total_records: totalCount,
      files_breakdown: Object.values(fileStats),
      files_count: Object.keys(fileStats).length,
      timestamp: new Date().toISOString()
    };

    console.log(`üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: ${totalCount} records ‡∏à‡∏≤‡∏Å ${Object.keys(fileStats).length} ‡πÑ‡∏ü‡∏•‡πå`);

    return NextResponse.json({ 
      message: `‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ${totalCount} records ‡∏à‡∏≤‡∏Å ${Object.keys(fileStats).length} ‡πÑ‡∏ü‡∏•‡πå`,
      stats,
      success: true
    })

  } catch (error) {
    console.error('‚ùå Error ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏π‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:', error)
    
    return NextResponse.json({ 
      error: '‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏π‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•',
      details: error instanceof Error ? error.message : 'Unknown error',
      success: false
    }, { status: 500 })
  }
}